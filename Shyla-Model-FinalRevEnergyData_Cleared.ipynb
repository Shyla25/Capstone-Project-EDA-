{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "587aa525-655d-4c7e-984d-27ef14af960a",
   "metadata": {},
   "source": [
    "#### Energy Data Machine Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b512802-48e0-4c8f-b9a9-e30bb09ec0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502b5dc8-58bc-4af3-baae-712041483f0f",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f0432-b667-4188-95d3-7bc35c734b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-load the data set\n",
    "df = pd.read_csv('energydata.csv')\n",
    "\n",
    "# Convert 'date' column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y %H:%M', errors='coerce')\n",
    "\n",
    "# Extract numerical features from the 'date' column\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df['hour'] = df['date'].dt.hour\n",
    "df['minute'] = df['date'].dt.minute\n",
    "\n",
    "# Create a copy of the dataframe\n",
    "df_new = df.copy()\n",
    "\n",
    "# Reset index of the new dataframe\n",
    "df_new_reset = df_new.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c36f1e-29fc-4b32-9630-38160abf55c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the feature matrix and target vector\n",
    "X = df_new.drop(columns=['Appliances', 'year', 'date'])  # Exclude the target and year column\n",
    "y = df_new['Appliances']  # Target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784081b-5fbd-4f42-b01c-f9da4c2e8555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top features for training (from MI and RFE)\n",
    "top_features = ['hour', 'T9', 'T7', 'RH_6', 'T5', 'T4', 'T8', 'T1', 'T3', 'RH_1', 'Press_mm_hg', 'T_out', 'T2', 'RH_8', 'RH_5']\n",
    "\n",
    "# Get X_train with only the selected features\n",
    "X_train_df = X[top_features]\n",
    "\n",
    "# Ensure y matches the shape of X_train_df\n",
    "y = df_new['Appliances'][:len(X_train_df)]  # Adjust y to have the same number of rows as X_train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969d7b7-a4e0-4f64-9f3d-19088fba262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now split the data, ensuring both X_train_df and y are consistently split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_train_df, y, test_size=0.3, random_state=42)\n",
    "X_eval, X_test, y_eval, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b92f2f-a71e-4e36-b34d-2ccdaa5b4dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shapes of the resulting splits\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_eval shape:\", X_eval.shape)\n",
    "print(\"y_eval shape:\", y_eval.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9431020-bdee-4eb6-8b69-fc87f2eaa43a",
   "metadata": {},
   "source": [
    "#### SVM with the radial basis function (RBF) kernel without hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1997e953-27a0-4de5-8398-c234eb0abb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features (important for SVM)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Scaling for training set\n",
    "X_eval_scaled = scaler.transform(X_eval)  # Scaling for evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba3905-855f-421c-9294-76afa4633418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the SVM model with RBF kernel (default parameters)\n",
    "svm_model = SVR(kernel='rbf')\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d749e-55fe-4c44-b926-394538263347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions on the evaluation set\n",
    "y_eval_pred = svm_model.predict(X_eval_scaled)\n",
    "\n",
    "#Evaluate the model on the evaluation set\n",
    "mse = mean_squared_error(y_eval, y_eval_pred)\n",
    "r2 = r2_score(y_eval, y_eval_pred)\n",
    "\n",
    "print(f\"Mean Squared Error on Evaluation Set: {mse}\")\n",
    "print(f\"R-squared on Evaluation Set: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d32094a-f785-4852-8b17-9cf9b07c9182",
   "metadata": {},
   "source": [
    "- Base SVM got poor result, will now do SVM with tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57c558a-cc05-4284-add7-c0fc423c1d45",
   "metadata": {},
   "source": [
    "#### SVM Tuning with cv=5 and 18 fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecc28d8-35a5-457a-9d7a-84ec466c9286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuning the SVM with cross-validation and multiple fits\n",
    "\n",
    "# Set up parameter grid for SVR\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'epsilon': [0.01, 0.1, 0.2],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search = GridSearchCV(SVR(), param_grid, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best parameters and model\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "svr_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2784fdb-f735-470d-adc6-5340f4e376c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the evaluation set\n",
    "y_pred = svr_model.predict(X_eval_scaled)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse = mean_squared_error(y_eval, y_pred)\n",
    "r2 = r2_score(y_eval, y_pred)\n",
    "\n",
    "# Output the evaluation metrics\n",
    "print(f\"Mean Squared Error on Evaluation Set: {mse}\")\n",
    "print(f\"R-squared on Evaluation Set: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a9abc0-50aa-4534-9290-667bef9cfe9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.n_splits_)  # Number of cross-validation splits\n",
    "print(len(grid_search.cv_results_['mean_test_score']))  # Total number of fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ca04f-d06a-4ffa-908c-393545c1da83",
   "metadata": {},
   "source": [
    "##### Summary of SVM on the Training Set:\n",
    "- SVM with kernel='rbf', C=1.0, epsilon=0.1, got poor result with MSE = 8213.612075235185 and r^2 = 0.03: meaning the model is not fitting well.\n",
    "- SVM is tuned with 5-cross validation and total 18 fits, with  best parameters C'= 10, 'epsilon'= 0.2, 'gamma'= 'scale, slightly improved the result but still not acceptable with MSE = 7659 and 2^ at 0.10.\n",
    "- Possible reasons could be that SVM struggle with high dimension data (training set at 13,814 rows and 15 columns) and the complex relationship of the features.\n",
    "- Next step is to explore tree based models that are more capable in handling high dimension and complex data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b03552-1c4c-4a9d-a793-52bff8184c8e",
   "metadata": {},
   "source": [
    "### Tree-Based Models (Random Forest, XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122988e-622d-403c-95fa-177c2263e8bc",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633c6b0a-bdbc-4df9-8843-2c64b30ddea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Regressor model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model with the training data\n",
    "rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b713c53-c413-4b1b-a1bb-ea4ba3db0582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the evaluation set\n",
    "y_eval_pred = rf_model.predict(X_eval_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) and R-squared (RÂ²)\n",
    "mse = mean_squared_error(y_eval, y_eval_pred)\n",
    "r2 = r2_score(y_eval, y_eval_pred)\n",
    "\n",
    "print(f\"Mean Squared Error on Evaluation Set: {mse}\")\n",
    "print(f\"R-squared on Evaluation Set: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c062e875-98cc-4c67-9d0d-f93cfef44aa0",
   "metadata": {},
   "source": [
    "- Random Forest has improved both MSE and r^2 with RMSE=3,880 and r^=0.55\n",
    "- Will try to get better resukt with hyperparameter tuning of Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faf2050-d3f3-4c81-91fe-b823d0cbfa57",
   "metadata": {},
   "source": [
    "#### Random Forest with Hyperparameter Tuning: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f127b3-803c-4baa-89b5-02c560f4c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF tuning with parammeter distrubution listed below at cv=5, iter=50\n",
    "\n",
    "# Set up the parameter distribution for Random Forest\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [None, 10, 20, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 6]\n",
    "}\n",
    "\n",
    "# Set up the Randomized Search with 5 cross-validation folds\n",
    "random_search = RandomizedSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
    "                                   param_distributions=param_dist, \n",
    "                                   n_iter=50, cv=5, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe8110-4be8-46fb-9ffc-a12108acf717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters and best model\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "rf_best_model_random = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the tuned model\n",
    "y_eval_pred_random = rf_best_model_random.predict(X_eval_scaled)\n",
    "mse_random = mean_squared_error(y_eval, y_eval_pred_random)\n",
    "r2_random = r2_score(y_eval, y_eval_pred_random)\n",
    "\n",
    "print(f\"Mean Squared Error on Evaluation Set (Randomized Tuned): {mse_random}\")\n",
    "print(f\"R-squared on Evaluation Set (Randomized Tuned): {r2_random}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962d8ddf-e86e-4c12-8200-e05facc45bf2",
   "metadata": {},
   "source": [
    "- With best parameters from RandmozedSearchCV of Random Forest, MSE = 3,823, while r^2=0.553. This is a slight improvemen with the base RF model.\n",
    "- Next will explore further with tree-based model now using XG boost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa5ede8-fcb9-4e19-92f3-845b40f7077b",
   "metadata": {},
   "source": [
    "#### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee8fff-2791-4904-86f7-f56fd1270c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0839b896-173d-487b-8a21-8b364b12123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with default parameters\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the evaluation set\n",
    "y_eval_pred = xgb_model.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2a5dc8-74b2-4193-a70b-ccad35d7f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "mse_eval = mean_squared_error(y_eval, y_eval_pred)\n",
    "r2_eval = r2_score(y_eval, y_eval_pred)\n",
    "\n",
    "print(f\"Mean Squared Error on Evaluation Set: {mse_eval}\")\n",
    "print(f\"R-squared on Evaluation Set: {r2_eval}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b99cd5-b4f4-46aa-86c8-32901ae0c628",
   "metadata": {},
   "source": [
    "#### XG Boost with Reduced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1536c2-0c15-40d9-b7ac-4072adae652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further reducing features using Recursive Feauture Elimination (currently selection is 15) to increase MSE and R^2\n",
    "\n",
    "#Train a Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances\n",
    "feature_importances = rf.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': top_features, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Select top N important features (e.g., top 10)\n",
    "top_selected_features = feature_importance_df['Feature'].head(10).tolist()\n",
    "\n",
    "print(\"Top selected features:\", top_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0068ef70-545e-4f68-b75f-5a5c4fbc0019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading the data set to use the 10 features\n",
    "# Re-load the data set\n",
    "df = pd.read_csv('energydata.csv')\n",
    "\n",
    "# Convert 'date' column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y %H:%M', errors='coerce')\n",
    "\n",
    "# Extract numerical features from the 'date' column\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df['hour'] = df['date'].dt.hour\n",
    "df['minute'] = df['date'].dt.minute\n",
    "\n",
    "# Create a copy of the dataframe\n",
    "df_new = df.copy()\n",
    "\n",
    "# Reset index of the new dataframe\n",
    "df_new_reset = df_new.reset_index(drop=True)\n",
    "# Prepare the feature matrix and target vector\n",
    "X = df_new.drop(columns=['Appliances', 'year', 'date'])  # Exclude the target and year column\n",
    "y = df_new['Appliances']  # Target variable\n",
    "# Select top features for training (from MI and RFE)\n",
    "top_features = ['hour', 'Press_mm_hg', 'T_out', 'T3', 'RH_1', 'RH_5', 'T8', 'RH_8', 'RH_6', 'T4']\n",
    "# Get X_train with only the selected features\n",
    "X_train_df = X[top_features]\n",
    "\n",
    "# Ensure y matches the shape of X_train_df\n",
    "y = df_new['Appliances'][:len(X_train_df)]  # Adjust y to have the same number of rows as X_train_df\n",
    "\n",
    "# Now split the data, ensuring both X_train_df and y are consistently split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_train_df, y, test_size=0.3, random_state=42)\n",
    "X_eval, X_test, y_eval, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ab555-775f-4c62-b88f-ffd58195f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shapes of the resulting splits\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_eval shape:\", X_eval.shape)\n",
    "print(\"y_eval shape:\", y_eval.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f018c1-278a-4392-bf00-19886ef58665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model with default parameters\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the evaluation set\n",
    "y_eval_pred = xgb_model.predict(X_eval)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_eval = mean_squared_error(y_eval, y_eval_pred)\n",
    "r2_eval = r2_score(y_eval, y_eval_pred)\n",
    "\n",
    "print(f\"Mean Squared Error on Evaluation Set: {mse_eval}\")\n",
    "print(f\"R-squared on Evaluation Set: {r2_eval}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7ed86f-7130-4b27-86cf-a5590a710684",
   "metadata": {},
   "source": [
    "- Implementing reduced features (using 10 most impt from the re-run Recursive Featue elimination) did not greatly improved the MSE and r^2.\n",
    "- Next approcah is tune the XG boost with GridsearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c665e6-dab3-4091-af3e-68bde36cb0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the parameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.5],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1],\n",
    "    'reg_lambda': [1, 1.5, 2, 5]\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost regressor\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Use RandomizedSearchCV for hyperparameter tuning\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,  # Number of parameter combinations to try\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd70b4-3c7b-4703-8818-6f2c423bc1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model and parameters\n",
    "best_xgb = random_search.best_estimator_\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate on the evaluation set\n",
    "y_pred_eval = best_xgb.predict(X_eval)\n",
    "mse_eval = mean_squared_error(y_eval, y_pred_eval)\n",
    "r2_eval = r2_score(y_eval, y_pred_eval)\n",
    "\n",
    "print(\"Mean Squared Error on Evaluation Set (Tuned XGBoost):\", mse_eval)\n",
    "print(\"R-squared on Evaluation Set (Tuned XGBoost):\", r2_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380559b6-2b7a-4c4c-9a54-9e358fd7a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model and parameters\n",
    "best_xgb = random_search.best_estimator_\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate on the evaluation set\n",
    "y_pred_eval = best_xgb.predict(X_eval)\n",
    "mse_eval = mean_squared_error(y_eval, y_pred_eval)\n",
    "r2_eval = r2_score(y_eval, y_pred_eval)\n",
    "\n",
    "print(\"Mean Squared Error on Evaluation Set (Tuned XGBoost):\", mse_eval)\n",
    "print(\"R-squared on Evaluation Set (Tuned XGBoost):\", r2_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3220f443-baec-4d09-b593-5d3f976bdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#further tuning XG-boost\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [400, 500, 600],\n",
    "    'learning_rate': [0.05, 0.08, 0.1, 0.12],\n",
    "    'max_depth': [8, 9, 10, 11, 12],\n",
    "    'subsample': [0.5, 0.6, 0.7],\n",
    "    'colsample_bytree': [0.5, 0.6, 0.7],\n",
    "    'gamma': [0.1, 0.2, 0.3],\n",
    "    'reg_alpha': [0.4, 0.5, 0.6],\n",
    "    'reg_lambda': [4, 5, 6]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(objective='reg:squarederror', random_state=42),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,  # Fewer iterations but in a smaller range\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d5b8d-668c-4292-8284-4772d29d02d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model\n",
    "best_xgb = random_search.best_estimator_\n",
    "print(\"New Best parameters:\", random_search.best_params_)\n",
    "\n",
    "# Evaluate again\n",
    "y_pred_eval = best_xgb.predict(X_eval)\n",
    "mse_eval = mean_squared_error(y_eval, y_pred_eval)\n",
    "r2_eval = r2_score(y_eval, y_pred_eval)\n",
    "\n",
    "print(\"Fine-Tuned Mean Squared Error:\", mse_eval)\n",
    "print(\"Fine-Tuned R-squared:\", r2_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd14d95-1d73-4ce9-93b0-5be4676ba070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before further continuing with XG-boost tuning, taking a look at the residual p`attern of y_train predict.\n",
    "\n",
    "# Predict on the training data\n",
    "y_train_pred = best_xgb.predict(X_train)\n",
    "\n",
    "# Calculate residuals for the training data\n",
    "residuals_train = y_train - y_train_pred\n",
    "\n",
    "# Plot residuals vs predicted values (training data)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_train_pred, residuals_train, color='blue', alpha=0.5)\n",
    "plt.axhline(y=0, color='red', linestyle='--')  # Line at y=0\n",
    "plt.title('Residuals vs. Predicted Values (Training Data)')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()\n",
    "\n",
    "# the residuals seems to forma pattern with heavy dense dots from 0-400 at X-axis while showing slight \n",
    "#randomness at 600 predicted values. From here, resuals are scattered at 0-50 range.\n",
    "#This could mean that the model may be underfitting or failing to capture certain relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d740ad32-cc57-4c3f-92ee-91602c187200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the residuals (training data)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals_train, kde=True, bins=30, color='blue')\n",
    "plt.title('Histogram of Residuals (Training Data)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "#The histogram of the residuals has almost normal distrubution centered at 0 , but slightly skewed to the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee96770-093c-4b85-b4ec-c7bb2e53febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "#Further looking in to the residuals\n",
    "# Q-Q plot (training data residuals)\n",
    "plt.figure(figsize=(10, 6))\n",
    "stats.probplot(residuals_train, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals (Training Data)')\n",
    "plt.show()\n",
    "\n",
    "#the heavy tails (downward and upward direction) of the Q-Q plot may indicate problematic outliers that could distort model performance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cf5c5b-0d87-47c9-af25-3639a46a19ad",
   "metadata": {},
   "source": [
    "- The residual plot summary indicates that:\n",
    "  1. residual scatter plot, not random = adjust the model or do further feature engineering.\n",
    "  2. histogram = centered at 0 but bins are not uniform on each side, showing slight skewed to the left, thus suggeting that the model is systematically underestimating the lower values of the target variable.\n",
    "  3. One tail upward, suggesting outleiers and downward on the other suggesting  skewness.\n",
    "\n",
    "- From these results, we will apply log transformation to address skweness. If this does not work, we will re-visit the features. Residuals forming pattern and not randomly scettrred could mean underfitting or missing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946865f6-8556-4b53-965c-b256547a8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log transformation to the target variable\n",
    "y_train_log = np.log(y_train + 1)  # Adding 1 to avoid log(0) if there are any zeros in y_train\n",
    "\n",
    "# Define the XGBoost model with your best hyperparameters\n",
    "model = XGBRegressor(\n",
    "    subsample=0.6,\n",
    "    reg_lambda=6,\n",
    "    reg_alpha=0.4,\n",
    "    n_estimators=600,\n",
    "    max_depth=12,\n",
    "    learning_rate=0.08,\n",
    "    gamma=0.2,\n",
    "    colsample_bytree=0.6\n",
    ")\n",
    "\n",
    "# Train the model on the transformed target variable\n",
    "model.fit(X_train, y_train_log)\n",
    "\n",
    "# Predict on the training data using the log-transformed model\n",
    "y_train_pred_log = model.predict(X_train)\n",
    "\n",
    "# Calculate residuals for the log-transformed data\n",
    "residuals_log = y_train_log - y_train_pred_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad1a33-e235-4983-909b-b6711a63ce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals vs predicted values (log-transformed target)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_train_pred_log, residuals_log, color='blue', alpha=0.5)\n",
    "plt.axhline(y=0, color='red', linestyle='--')  # Line at y=0\n",
    "plt.title('Residuals vs. Predicted Values (Log-transformed Target)')\n",
    "plt.xlabel('Predicted Values (Log)')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36bc8e8-2ce3-4048-b50b-37e302625d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the residuals (log-transformed target)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals_log, kde=True, bins=30, color='blue')\n",
    "plt.title('Histogram of Residuals (Log-transformed Target)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a0238-1925-48a2-aff3-ee496f455d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Q plot (log-transformed target residuals)\n",
    "plt.figure(figsize=(10, 6))\n",
    "stats.probplot(residuals_log, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals (Log-transformed Target)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07def980-868b-497e-8379-76a42f5fdad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle the cyclic hour feature by creating hour_sin and hour_cos\n",
    "X_train['hour_sin'] = np.sin(2 * np.pi * X_train['hour'] / 24)  # Create cyclic feature for hour\n",
    "X_train['hour_cos'] = np.cos(2 * np.pi * X_train['hour'] / 24)  # Create cyclic feature for hour\n",
    "\n",
    "# Same for evaluation set\n",
    "X_eval['hour_sin'] = np.sin(2 * np.pi * X_eval['hour'] / 24)\n",
    "X_eval['hour_cos'] = np.cos(2 * np.pi * X_eval['hour'] / 24)\n",
    "\n",
    "# Replace zeros with a small constant (1e-5) in the log-transformed columns before applying log1p\n",
    "log_columns = X_train.columns.difference(['hour_sin', 'hour_cos'])  # Exclude hour_sin and hour_cos\n",
    "X_train[log_columns] = X_train[log_columns].replace(0, 1e-5)  # Replace zeros in training set\n",
    "X_eval[log_columns] = X_eval[log_columns].replace(0, 1e-5)    # Replace zeros in evaluation set\n",
    "\n",
    "# Handle negative values by replacing them with a small constant (1e-5)\n",
    "X_train[log_columns] = X_train[log_columns].where(X_train[log_columns] >= 0, 1e-5)  # Handle negative values\n",
    "X_eval[log_columns] = X_eval[log_columns].where(X_eval[log_columns] >= 0, 1e-5)    # Handle negative values\n",
    "\n",
    "# Apply log transformation to non-cyclic features\n",
    "log_columns = X_train.columns.difference(['hour_sin', 'hour_cos'])  # Exclude hour_sin and hour_cos\n",
    "X_train_log = X_train.copy()\n",
    "X_train_log[log_columns] = np.log1p(X_train[log_columns])  # Log transformation for non-cyclic columns\n",
    "\n",
    "# Apply the same log transformation to the evaluation set\n",
    "X_eval_log = X_eval.copy()\n",
    "X_eval_log[log_columns] = np.log1p(X_eval[log_columns])  # Log transformation for non-cyclic columns\n",
    "\n",
    "# Shift the target variable to avoid log(0)\n",
    "y_train_log = np.log1p(y_train)  # Apply log1p to target variable y_train\n",
    "y_eval_log = np.log1p(y_eval)    # Apply log1p to target variable y_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e5f0f5-7618-4c2d-9f9d-c64e094c256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XGBoost model\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    subsample=0.6,\n",
    "    reg_lambda=6,\n",
    "    reg_alpha=0.4,\n",
    "    n_estimators=600,\n",
    "    max_depth=12,\n",
    "    learning_rate=0.08,\n",
    "    gamma=0.2,\n",
    "    colsample_bytree=0.6\n",
    ")\n",
    "# Train the model on log-transformed training data\n",
    "model.fit(X_train_log, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19494a7b-c94b-450b-90a5-27fe627e28e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the evaluation data\n",
    "y_eval_pred = model.predict(X_eval_log)\n",
    "\n",
    "# Evaluate the model performance on the evaluation set\n",
    "mse_eval = mean_squared_error(y_eval_log, y_eval_pred)\n",
    "r2_eval = r2_score(y_eval_log, y_eval_pred)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Evaluation Set MSE: {mse_eval}\")\n",
    "print(f\"Evaluation Set R-squared: {r2_eval}\")\n",
    "\n",
    "#The result has better MSE and r^2, from this we can tune the model further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb60340e-0ec9-4c47-999d-0a3849b9e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#further tuning of XG Boost\n",
    "\n",
    "#Define the model\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Define the hyperparameters grid for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(100, 1001, 100),           # Number of trees in boosting rounds\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],        # Step size shrinking\n",
    "    'max_depth': [3, 5, 7, 9, 10],                        # Maximum depth of the tree\n",
    "    'min_child_weight': [1, 2, 3, 4, 5],                  # Minimum sum of instance weight\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],              # Fraction of training samples for each tree\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],       # Fraction of features for each tree\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],                    # Minimum loss reduction\n",
    "    'scale_pos_weight': [1, 2, 3],                        # Scale the positive weight (useful for imbalanced data)\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, n_iter=10, cv=5, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model to the training data\n",
    "random_search.fit(X_train_log, y_train_log)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99c48c6-39ce-486f-8139-245ffb3afc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from RandomizedSearchCV\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "\n",
    "# Predict on the evaluation set\n",
    "y_eval_pred = best_xgb_model.predict(X_eval_log)\n",
    "\n",
    "# Calculate MSE and R-squared for the evaluation set\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse_eval = mean_squared_error(y_eval_log, y_eval_pred)\n",
    "r2_eval = r2_score(y_eval_log, y_eval_pred)\n",
    "\n",
    "print(f\"Evaluation Set MSE: {mse_eval}\")\n",
    "print(f\"Evaluation Set R-squared: {r2_eval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e093d0ac-b38c-45e7-9ae1-2cbe967781e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on training set\n",
    "y_train_pred = best_xgb_model.predict(X_train_log)\n",
    "y_eval_pred = best_xgb_model.predict(X_eval_log)\n",
    "\n",
    "mse_train = mean_squared_error(y_train_log, y_train_pred)\n",
    "r2_train = r2_score(y_train_log, y_train_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Training Set MSE: {mse_train}\")\n",
    "print(f\"Training Set R-squared: {r2_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3865ead-75fd-4419-8309-466f84177238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training and evaluation sets\n",
    "y_train_pred = best_xgb_model.predict(X_train_log)\n",
    "y_eval_pred = best_xgb_model.predict(X_eval_log)\n",
    "\n",
    "# Plotting the predictions against the true values for training and evaluation sets\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Training set plot\n",
    "axs[0].scatter(y_train_log, y_train_pred, color='blue', alpha=0.6)\n",
    "axs[0].plot([y_train_log.min(), y_train_log.max()], [y_train_log.min(), y_train_log.max()], color='red', linestyle='--')\n",
    "axs[0].set_title(\"Training Set: True vs Predicted\")\n",
    "axs[0].set_xlabel(\"True values (y_train_log)\")\n",
    "axs[0].set_ylabel(\"Predicted values (y_train_pred)\")\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Evaluation set plot\n",
    "axs[1].scatter(y_eval_log, y_eval_pred, color='green', alpha=0.6)\n",
    "axs[1].plot([y_eval_log.min(), y_eval_log.max()], [y_eval_log.min(), y_eval_log.max()], color='red', linestyle='--')\n",
    "axs[1].set_title(\"Evaluation Set: True vs Predicted\")\n",
    "axs[1].set_xlabel(\"True values (y_eval_log)\")\n",
    "axs[1].set_ylabel(\"Predicted values (y_eval_pred)\")\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb82ae1-f365-4bb4-84ab-8ab34f50a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting both training and evaluation set predictions together\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot training set\n",
    "plt.scatter(y_train_log, y_train_pred, color='blue', alpha=0.6, label='Training Set', s=20)\n",
    "\n",
    "# Plot evaluation set\n",
    "plt.scatter(y_eval_log, y_eval_pred, color='green', alpha=0.6, label='Evaluation Set', s=20)\n",
    "\n",
    "# Plot a line for perfect prediction (y_true = y_pred)\n",
    "plt.plot([min(y_train_log.min(), y_eval_log.min()), max(y_train_log.max(), y_eval_log.max())],\n",
    "         [min(y_train_log.min(), y_eval_log.min()), max(y_train_log.max(), y_eval_log.max())],\n",
    "         color='red', linestyle='--', label='Perfect Prediction')\n",
    "\n",
    "# Set labels and title\n",
    "plt.title(\"True vs Predicted Values for Training and Evaluation Sets\")\n",
    "plt.xlabel(\"True values\")\n",
    "plt.ylabel(\"Predicted values\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fc88df-12c2-4c15-a6a8-fb6c5fc495c2",
   "metadata": {},
   "source": [
    "#### The tuned XGBoost showed overfitting as we can see from this  result:\n",
    "- Evaluation Set MSE: 0.19057607821743702\n",
    "- Evaluation Set R-squared: 0.5215629315035697\n",
    "- Training Set MSE: 0.06139894743900729\n",
    "- Training Set R-squared: 0.8532941635612186"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d439b7-b2b8-49da-a0a5-246a307eae73",
   "metadata": {},
   "source": [
    "- To address overfitting, lets try to\n",
    "  1. reduce depth\n",
    "  2. lower n_setimators\n",
    "  3. experiment on cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0ef9e8-5ea6-456d-91b3-654f76e33845",
   "metadata": {},
   "source": [
    "- XGBoost Hyper Parameter Tuning, reducing n_estimators, max_dept, and increase cv =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d5d577-1bab-479f-a18f-6c76744a98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Define the hyperparameters grid for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(50, 75 , 100),           # Number of trees in boosting rounds\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],        # Step size shrinking\n",
    "    'max_depth': [2, 4, 5, 6, 7],                        # Maximum depth of the tree\n",
    "    'min_child_weight': [1, 2, 3, 4, 5],                  # Minimum sum of instance weight\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],              # Fraction of training samples for each tree\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],       # Fraction of features for each tree\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],                    # Minimum loss reduction\n",
    "}    \n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, n_iter=10, cv=10, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model to the training data\n",
    "random_search.fit(X_train_log, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c74dff-59d3-4039-9908-c3ea0cdfd281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters and the corresponding score\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2aa32-c7d6-45b8-b6aa-8ea06d0ca539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from RandomizedSearchCV\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "\n",
    "# Predict on the evaluation set\n",
    "y_eval_pred = best_xgb_model.predict(X_eval_log)\n",
    "y_train_pred = best_xgb_model.predict(X_train_log)\n",
    "\n",
    "# Calculate MSE and R-squared for the evaluation set\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse_eval = mean_squared_error(y_eval_log, y_eval_pred)\n",
    "r2_eval = r2_score(y_eval_log, y_eval_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y_train_log, y_train_pred)\n",
    "r2_eval = r2_score(y_train_log, y_train_pred)\n",
    "\n",
    "print(f\"Evaluation Set MSE: {mse_eval}\")\n",
    "print(f\"Evaluation Set R-squared: {r2_eval}\")\n",
    "\n",
    "print(f\"Training Set MSE: {mse_train}\")\n",
    "print(f\"Training Set R-squared: {r2_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c37d1f-9067-42b9-a781-909ba9df5ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training and evaluation sets\n",
    "y_train_pred = best_xgb_model.predict(X_train_log)\n",
    "y_eval_pred = best_xgb_model.predict(X_eval_log)\n",
    "\n",
    "# Plotting the predictions against the true values for training and evaluation sets\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Training set plot\n",
    "axs[0].scatter(y_train_log, y_train_pred, color='blue', alpha=0.6)\n",
    "axs[0].plot([y_train_log.min(), y_train_log.max()], [y_train_log.min(), y_train_log.max()], color='red', linestyle='--')\n",
    "axs[0].set_title(\"Training Set: True vs Predicted\")\n",
    "axs[0].set_xlabel(\"True values (y_train_log)\")\n",
    "axs[0].set_ylabel(\"Predicted values (y_train_pred)\")\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Evaluation set plot\n",
    "axs[1].scatter(y_eval_log, y_eval_pred, color='green', alpha=0.6)\n",
    "axs[1].plot([y_eval_log.min(), y_eval_log.max()], [y_eval_log.min(), y_eval_log.max()], color='red', linestyle='--')\n",
    "axs[1].set_title(\"Evaluation Set: True vs Predicted\")\n",
    "axs[1].set_xlabel(\"True values (y_eval_log)\")\n",
    "axs[1].set_ylabel(\"Predicted values (y_eval_pred)\")\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa753f4-5728-4ba7-9131-e41a9029574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting both training and evaluation set predictions together\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot training set\n",
    "plt.scatter(y_train_log, y_train_pred, color='blue', alpha=0.6, label='Training Set', s=20)\n",
    "\n",
    "# Plot evaluation set\n",
    "plt.scatter(y_eval_log, y_eval_pred, color='green', alpha=0.6, label='Evaluation Set', s=20)\n",
    "\n",
    "# Plot a line for perfect prediction (y_true = y_pred)\n",
    "plt.plot([min(y_train_log.min(), y_eval_log.min()), max(y_train_log.max(), y_eval_log.max())],\n",
    "         [min(y_train_log.min(), y_eval_log.min()), max(y_train_log.max(), y_eval_log.max())],\n",
    "         color='red', linestyle='--', label='Perfect Prediction')\n",
    "\n",
    "# Set labels and title\n",
    "plt.title(\"True vs Predicted Values for Training and Evaluation Sets\")\n",
    "plt.xlabel(\"True values\")\n",
    "plt.ylabel(\"Predicted values\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24232f4a-f26c-4196-bee3-7d77bb087a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further tuning of hyperparameters, cv=10, n=estimators reduced, \n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Define the hyperparameters grid for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(300, 600 , 900),           # Number of trees in boosting rounds\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],        # Step size shrinking\n",
    "    'max_depth': [2, 4, 5, 6, 7],                        # Maximum depth of the tree\n",
    "    'min_child_weight': [1, 2, 3, 4, 5],                  # Minimum sum of instance weight\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],              # Fraction of training samples for each tree\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],       # Fraction of features for each tree\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],                    # Minimum loss reduction\n",
    "}    \n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, n_iter=10, cv=10, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model to the training data\n",
    "random_search.fit(X_train_log, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeebf66-771c-4444-b2ce-03ab671fd92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameters and the corresponding score\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89423294-a5cf-4dea-b2ce-8604180a1ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from RandomizedSearchCV\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "\n",
    "# Predict on the evaluation set\n",
    "y_eval_pred = best_xgb_model.predict(X_eval_log)\n",
    "y_train_pred = best_xgb_model.predict(X_train_log)\n",
    "\n",
    "# Calculate MSE and R-squared for the evaluation set\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse_eval = mean_squared_error(y_eval_log, y_eval_pred)\n",
    "r2_eval = r2_score(y_eval_log, y_eval_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y_train_log, y_train_pred)\n",
    "r2_eval = r2_score(y_train_log, y_train_pred)\n",
    "\n",
    "print(f\"Evaluation Set MSE: {mse_eval}\")\n",
    "print(f\"Evaluation Set R-squared: {r2_eval}\")\n",
    "\n",
    "print(f\"Training Set MSE: {mse_train}\")\n",
    "print(f\"Training Set R-squared: {r2_train}\")\n",
    "\n",
    "# Still slightly overfitting, tuning further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d507d4-98ba-4539-9ef2-7358d36a42df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions against the true values for training and evaluation sets\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Training set plot\n",
    "axs[0].scatter(y_train_log, y_train_pred, color='blue', alpha=0.6)\n",
    "axs[0].plot([y_train_log.min(), y_train_log.max()], [y_train_log.min(), y_train_log.max()], color='red', linestyle='--')\n",
    "axs[0].set_title(\"Training Set: True vs Predicted\")\n",
    "axs[0].set_xlabel(\"True values (y_train_log)\")\n",
    "axs[0].set_ylabel(\"Predicted values (y_train_pred)\")\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Evaluation set plot\n",
    "axs[1].scatter(y_eval_log, y_eval_pred, color='green', alpha=0.6)\n",
    "axs[1].plot([y_eval_log.min(), y_eval_log.max()], [y_eval_log.min(), y_eval_log.max()], color='red', linestyle='--')\n",
    "axs[1].set_title(\"Evaluation Set: True vs Predicted\")\n",
    "axs[1].set_xlabel(\"True values (y_eval_log)\")\n",
    "axs[1].set_ylabel(\"Predicted values (y_eval_pred)\")\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a37d3f-6661-43fe-8a63-28d103fc33ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting both training and evaluation set predictions together\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot training set\n",
    "plt.scatter(y_train_log, y_train_pred, color='blue', alpha=0.6, label='Training Set', s=20)\n",
    "\n",
    "# Plot evaluation set\n",
    "plt.scatter(y_eval_log, y_eval_pred, color='green', alpha=0.6, label='Evaluation Set', s=20)\n",
    "\n",
    "# Plot a line for perfect prediction (y_true = y_pred)\n",
    "plt.plot([min(y_train_log.min(), y_eval_log.min()), max(y_train_log.max(), y_eval_log.max())],\n",
    "         [min(y_train_log.min(), y_eval_log.min()), max(y_train_log.max(), y_eval_log.max())],\n",
    "         color='red', linestyle='--', label='Perfect Prediction')\n",
    "\n",
    "# Set labels and title\n",
    "plt.title(\"True vs Predicted Values for Training and Evaluation Sets\")\n",
    "plt.xlabel(\"True values\")\n",
    "plt.ylabel(\"Predicted values\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84216e-b353-4c23-b679-ab1a57198c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#still getting an overfitting issue, and to address it. we will try to removed redundant features, reduce max_dept/estimators, and incrase subsample\n",
    "\n",
    "# Get feature importance scores from the trained model\n",
    "feature_importance = random_search.best_estimator_.feature_importances_\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "importances_df = pd.DataFrame({'Feature': X_train_log.columns, 'Importance': feature_importance})\n",
    "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importances_df['Feature'], importances_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.gca().invert_yaxis()  # Highest importance at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d09a5ed-11e0-4ad3-9352-295004b64e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the whole code again of log transformmation then remove the hour as redundant feature\n",
    "\n",
    "# Handle the cyclic hour feature by creating hour_sin and hour_cos\n",
    "X_train['hour_sin'] = np.sin(2 * np.pi * X_train['hour'] / 24)  # Create cyclic feature for hour\n",
    "X_train['hour_cos'] = np.cos(2 * np.pi * X_train['hour'] / 24)  # Create cyclic feature for hour\n",
    "\n",
    "# Same for evaluation set\n",
    "X_eval['hour_sin'] = np.sin(2 * np.pi * X_eval['hour'] / 24)\n",
    "X_eval['hour_cos'] = np.cos(2 * np.pi * X_eval['hour'] / 24)\n",
    "\n",
    "# Drop the 'hour' column after creating the cyclic features\n",
    "X_train = X_train.drop(columns=['hour'])\n",
    "X_eval = X_eval.drop(columns=['hour'])\n",
    "\n",
    "# Replace zeros with a small constant (1e-5) in the log-transformed columns before applying log1p\n",
    "log_columns = X_train.columns.difference(['hour_sin', 'hour_cos'])  # Exclude hour_sin and hour_cos\n",
    "X_train[log_columns] = X_train[log_columns].replace(0, 1e-5)  # Replace zeros in training set\n",
    "X_eval[log_columns] = X_eval[log_columns].replace(0, 1e-5)    # Replace zeros in evaluation set\n",
    "\n",
    "# Handle negative values by replacing them with a small constant (1e-5)\n",
    "X_train[log_columns] = X_train[log_columns].where(X_train[log_columns] >= 0, 1e-5)  # Handle negative values\n",
    "X_eval[log_columns] = X_eval[log_columns].where(X_eval[log_columns] >= 0, 1e-5)    # Handle negative values\n",
    "\n",
    "# Apply log transformation to non-cyclic features\n",
    "log_columns = X_train.columns.difference(['hour_sin', 'hour_cos'])  # Exclude hour_sin and hour_cos\n",
    "X_train_log = X_train.copy()\n",
    "X_train_log[log_columns] = np.log1p(X_train[log_columns])  # Log transformation for non-cyclic columns\n",
    "\n",
    "# Apply the same log transformation to the evaluation set\n",
    "X_eval_log = X_eval.copy()\n",
    "X_eval_log[log_columns] = np.log1p(X_eval[log_columns])  # Log transformation for non-cyclic columns\n",
    "\n",
    "# Shift the target variable to avoid log(0)\n",
    "y_train_log = np.log1p(y_train)  # Apply log1p to target variable y_train\n",
    "y_eval_log = np.log1p(y_eval)    # Apply log1p to target variable y_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13021135-b58f-4a1b-a162-3e64c3c35aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 'hour' has been dropped. \n",
    "print(\"X_train_log columns:\", X_train_log.columns)\n",
    "print(\"X_eval_log columns:\", X_eval_log.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805c256-6def-4342-847a-ff0e1164ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the XGboost with tuned hyperparameter\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Define the hyperparameters grid for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(200, 400, 600),           # Number of trees in boosting rounds\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],        # Step size shrinking\n",
    "    'max_depth': [2, 3, 4, 5, 6],                        # Maximum depth of the tree\n",
    "    'min_child_weight': [1, 2, 3, 4, 5],                  # Minimum sum of instance weight\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],              # Fraction of training samples for each tree\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],       # Fraction of features for each tree\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],                    # Minimum loss reduction\n",
    "                            \n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, n_iter=10, cv=15, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model to the training data\n",
    "random_search.fit(X_train_log, y_train_log)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb6176f-7555-43b3-8a6c-e6a1b7cf64ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from RandomizedSearchCV\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "\n",
    "# Predict on the evaluation set\n",
    "y_eval_pred = best_xgb_model.predict(X_eval_log)\n",
    "y_train_pred = best_xgb_model.predict(X_train_log)\n",
    "\n",
    "# Calculate MSE and R-squared for the evaluation set\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse_eval = mean_squared_error(y_eval_log, y_eval_pred)\n",
    "r2_eval = r2_score(y_eval_log, y_eval_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y_train_log, y_train_pred)\n",
    "r2_eval = r2_score(y_train_log, y_train_pred)\n",
    "\n",
    "print(f\"Evaluation Set MSE: {mse_eval}\")\n",
    "print(f\"Evaluation Set R-squared: {r2_eval}\")\n",
    "\n",
    "print(f\"Training Set MSE: {mse_train}\")\n",
    "print(f\"Training Set R-squared: {r2_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfb2dc7-7f4d-4d27-90d6-a47f61a975a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further tuning of hyper parameters\n",
    "\n",
    "# Updated parameter grid with more refined values\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(300, 501, 100),  # Increase n_estimators range\n",
    "    'learning_rate': [0.05, 0.1],               # Lower learning rate\n",
    "    'max_depth': [4, 5],                        # Try smaller max_depth\n",
    "    'min_child_weight': [5, 6],                  # Increase min_child_weight slightly\n",
    "    'subsample': [0.7, 0.8],                    # Try slightly higher subsample\n",
    "    'colsample_bytree': [0.7, 0.8],             # Try slightly higher colsample\n",
    "    'gamma': [0, 0.1, 0.2],                     # Add some regularization with gamma\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV with refined parameters\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, n_iter=10, cv=10, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model to the training data\n",
    "random_search.fit(X_train_log, y_train_log)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0627c29-be05-4b01-81e8-0eb11e0d9a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from RandomizedSearchCV\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "\n",
    "# Predict on the evaluation set\n",
    "y_eval_pred = best_xgb_model.predict(X_eval_log)\n",
    "y_train_pred = best_xgb_model.predict(X_train_log)\n",
    "\n",
    "# Calculate MSE and R-squared for the evaluation set\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse_eval = mean_squared_error(y_eval_log, y_eval_pred)\n",
    "r2_eval = r2_score(y_eval_log, y_eval_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y_train_log, y_train_pred)\n",
    "r2_eval = r2_score(y_train_log, y_train_pred)\n",
    "\n",
    "print(f\"Evaluation Set MSE: {mse_eval}\")\n",
    "print(f\"Evaluation Set R-squared: {r2_eval}\")\n",
    "\n",
    "print(f\"Training Set MSE: {mse_train}\")\n",
    "print(f\"Training Set R-squared: {r2_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caba52e-2838-4ccc-8777-fe92f055b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions against the true values for training and evaluation sets\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Training set plot\n",
    "axs[0].scatter(y_train_log, y_train_pred, color='blue', alpha=0.6)\n",
    "axs[0].plot([y_train_log.min(), y_train_log.max()], [y_train_log.min(), y_train_log.max()], color='red', linestyle='--')\n",
    "axs[0].set_title(\"Training Set: True vs Predicted\")\n",
    "axs[0].set_xlabel(\"True values (y_train_log)\")\n",
    "axs[0].set_ylabel(\"Predicted values (y_train_pred)\")\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Evaluation set plot\n",
    "axs[1].scatter(y_eval_log, y_eval_pred, color='green', alpha=0.6)\n",
    "axs[1].plot([y_eval_log.min(), y_eval_log.max()], [y_eval_log.min(), y_eval_log.max()], color='red', linestyle='--')\n",
    "axs[1].set_title(\"Evaluation Set: True vs Predicted\")\n",
    "axs[1].set_xlabel(\"True values (y_eval_log)\")\n",
    "axs[1].set_ylabel(\"Predicted values (y_eval_pred)\")\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7ad7b-5bb4-4d37-b7d6-9929eb2463ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting both training and evaluation set predictions together\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot training set\n",
    "plt.scatter(y_train_log, y_train_pred, color='blue', alpha=0.6, label='Training Set', s=20)\n",
    "\n",
    "# Plot evaluation set\n",
    "plt.scatter(y_eval_log, y_eval_pred, color='green', alpha=0.6, label='Evaluation Set', s=20)\n",
    "\n",
    "# Plot a line for perfect prediction (y_true = y_pred)\n",
    "plt.plot([min(y_train_log.min(), y_eval_log.min()), max(y_train_log.max(), y_eval_log.max())],\n",
    "         [min(y_train_log.min(), y_eval_log.min()), max(y_train_log.max(), y_eval_log.max())],\n",
    "         color='red', linestyle='--', label='Perfect Prediction')\n",
    "\n",
    "# Set labels and title\n",
    "plt.title(\"True vs Predicted Values for Training and Evaluation Sets\")\n",
    "plt.xlabel(\"True values\")\n",
    "plt.ylabel(\"Predicted values\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97fdabf-8a1a-4043-b923-c21ce003a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#More tuning as the result is still overfitting\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(200, 401, 100),  # Decrease n_estimators range\n",
    "    'learning_rate': [0.05, 0.1],               # Continue with small learning rates\n",
    "    'max_depth': [3, 4],                        # Reduce max_depth further\n",
    "    'min_child_weight': [6, 7],                  # Increase min_child_weight slightly\n",
    "    'subsample': [0.7, 0.8],                    # Keep subsample around 0.7 or 0.8\n",
    "    'colsample_bytree': [0.7, 0.8],             # Keep colsample_bytree moderate\n",
    "    'gamma': [0.1, 0.2],                        # Increase gamma for more regularization\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV with refined parameters\n",
    "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, n_iter=15, cv=5, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model to the training data\n",
    "random_search.fit(X_train_log, y_train_log)\n",
    "\n",
    "# Print the best parameters and the corresponding score\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630740fa-f558-4cdc-935a-12e6e7dc7885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from RandomizedSearchCV\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "\n",
    "# Predict on the evaluation set\n",
    "y_eval_pred = best_xgb_model.predict(X_eval_log)\n",
    "y_train_pred = best_xgb_model.predict(X_train_log)\n",
    "\n",
    "# Calculate MSE and R-squared for the evaluation set\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse_eval = mean_squared_error(y_eval_log, y_eval_pred)\n",
    "r2_eval = r2_score(y_eval_log, y_eval_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y_train_log, y_train_pred)\n",
    "r2_eval = r2_score(y_train_log, y_train_pred)\n",
    "\n",
    "print(f\"Evaluation Set MSE: {mse_eval}\")\n",
    "print(f\"Evaluation Set R-squared: {r2_eval}\")\n",
    "\n",
    "print(f\"Training Set MSE: {mse_train}\")\n",
    "print(f\"Training Set R-squared: {r2_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8f436-6a24-4433-af5b-4e6506e40acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters grid for RandomizedSearchCV with fewer parameters\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(100, 1001, 100),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # Restrict to lower values\n",
    "    'max_depth': [3, 5, 7],                    # Try fewer depth levels\n",
    "    'subsample': [0.6, 0.7, 0.8],              # Range for subsample\n",
    "    'colsample_bytree': [0.6, 0.7],            # Fraction of features to use\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV with fewer iterations and folds\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=15,  # Reduced n_iter\n",
    "    cv=5,       # Lower cv back to 5\n",
    "    verbose=2, \n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the randomized search to the training data\n",
    "random_search.fit(X_train_log, y_train_log)\n",
    "\n",
    "# Print the best hyperparameters and the best cross-validation score\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25b414-ba3a-4682-80d2-0ca984b33128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from RandomizedSearchCV\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "\n",
    "# Predict on the evaluation set\n",
    "y_eval_pred = best_xgb_model.predict(X_eval_log)\n",
    "y_train_pred = best_xgb_model.predict(X_train_log)\n",
    "\n",
    "# Calculate MSE and R-squared for the evaluation set\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mse_eval = mean_squared_error(y_eval_log, y_eval_pred)\n",
    "r2_eval = r2_score(y_eval_log, y_eval_pred)\n",
    "\n",
    "mse_train = mean_squared_error(y_train_log, y_train_pred)\n",
    "r2_eval = r2_score(y_train_log, y_train_pred)\n",
    "\n",
    "print(f\"Evaluation Set MSE: {mse_eval}\")\n",
    "print(f\"Evaluation Set R-squared: {r2_eval}\")\n",
    "\n",
    "print(f\"Training Set MSE: {mse_train}\")\n",
    "print(f\"Training Set R-squared: {r2_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca3b27-72ec-49d7-b4b2-b4aa6c7f4429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions against the true values for training and evaluation sets\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Training set plot\n",
    "axs[0].scatter(y_train_log, y_train_pred, color='blue', alpha=0.6)\n",
    "axs[0].plot([y_train_log.min(), y_train_log.max()], [y_train_log.min(), y_train_log.max()], color='red', linestyle='--')\n",
    "axs[0].set_title(\"Training Set: True vs Predicted\")\n",
    "axs[0].set_xlabel(\"True values (y_train_log)\")\n",
    "axs[0].set_ylabel(\"Predicted values (y_train_pred)\")\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Evaluation set plot\n",
    "axs[1].scatter(y_eval_log, y_eval_pred, color='green', alpha=0.6)\n",
    "axs[1].plot([y_eval_log.min(), y_eval_log.max()], [y_eval_log.min(), y_eval_log.max()], color='red', linestyle='--')\n",
    "axs[1].set_title(\"Evaluation Set: True vs Predicted\")\n",
    "axs[1].set_xlabel(\"True values (y_eval_log)\")\n",
    "axs[1].set_ylabel(\"Predicted values (y_eval_pred)\")\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17483d8-8349-40ca-931a-64c2de1f1f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting both training and evaluation set predictions together\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot training set\n",
    "plt.scatter(y_train_log, y_train_pred, color='blue', alpha=0.6, label='Training Set', s=20)\n",
    "\n",
    "# Plot evaluation set\n",
    "plt.scatter(y_eval_log, y_eval_pred, color='green', alpha=0.6, label='Evaluation Set', s=20)\n",
    "\n",
    "# Plot a line for perfect prediction (y_true = y_pred)\n",
    "plt.plot([min(y_train_log.min(), y_eval_log.min()), max(y_train_log.max(), y_eval_log.max())],\n",
    "         [min(y_train_log.min(), y_eval_log.min()), max(y_train_log.max(), y_eval_log.max())],\n",
    "         color='red', linestyle='--', label='Perfect Prediction')\n",
    "\n",
    "# Set labels and title\n",
    "plt.title(\"True vs Predicted Values for Training and Evaluation Sets\")\n",
    "plt.xlabel(\"True values\")\n",
    "plt.ylabel(\"Predicted values\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52b3078-05ef-4a40-bf25-dcff9b6ade66",
   "metadata": {},
   "source": [
    "- At last! This will be used to evaluate my test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652f012-343b-4c39-af22-4fe7a8ed0fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running the whole code again of log transformmation for the X_test\n",
    "\n",
    "# Handle the cyclic hour feature by creating hour_sin and hour_cos (before dropping the 'hour' column)\n",
    "X_test['hour_sin'] = np.sin(2 * np.pi * X_test['hour'] / 24)  # Create cyclic feature for hour\n",
    "X_test['hour_cos'] = np.cos(2 * np.pi * X_test['hour'] / 24)  # Create cyclic feature for hour\n",
    "\n",
    "# Drop the 'hour' column after creating the cyclic features (both in train and test sets)\n",
    "X_test = X_test.drop(columns=['hour'])\n",
    "\n",
    "# Replace zeros with a small constant (1e-5) in the log-transformed columns before applying log1p\n",
    "X_test[log_columns] = X_test[log_columns].replace(0, 1e-5)    # Replace zeros in test set\n",
    "\n",
    "# Handle negative values by replacing them with a small constant (1e-5)\n",
    "X_test[log_columns] = X_test[log_columns].where(X_test[log_columns] >= 0, 1e-5)    # Handle negative values\n",
    "\n",
    "# Apply the same log transformation to the test set\n",
    "X_test_log = X_test.copy()\n",
    "X_test_log[log_columns] = np.log1p(X_test_log[log_columns])  # Log transformation for non-cyclic columns\n",
    "\n",
    "# Shift the target variable to avoid log(0)\n",
    "y_train_log = np.log1p(y_train)  # Apply log1p to target variable y_train\n",
    "y_test_log = np.log1p(y_test)    # Apply log1p to target variable y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83b88d7-5fde-4768-bc56-01c7117250b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters grid for RandomizedSearchCV with fewer parameters\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(100, 1001, 100),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # Restrict to lower values\n",
    "    'max_depth': [3, 5, 7],                    # Try fewer depth levels\n",
    "    'subsample': [0.6, 0.7, 0.8],              # Range for subsample\n",
    "    'colsample_bytree': [0.6, 0.7],            # Fraction of features to use\n",
    "}\n",
    "\n",
    "# Initialize RandomizedSearchCV with fewer iterations and folds\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=15,  # Reduced n_iter\n",
    "    cv=5,       # Lower cv back to 5\n",
    "    verbose=2, \n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abc2a6a-9d6e-42af-b2fd-3ba17bc92a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the randomized search to the training data\n",
    "random_search.fit(X_train_log, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c5df97-02b8-4ad0-9ad4-5f95747499c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters and the best cross-validation score\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {random_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e404659-bbd5-4077-b88e-76ada54f0a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from RandomizedSearchCV\n",
    "best_xgb_model = random_search.best_estimator_\n",
    "\n",
    "# Predict on the test set and training set\n",
    "y_test_pred = best_xgb_model.predict(X_test_log)\n",
    "y_train_pred = best_xgb_model.predict(X_train_log)\n",
    "\n",
    "# Test set MSE and R-squared\n",
    "mse_test = mean_squared_error(y_test_log, y_test_pred)\n",
    "r2_test = r2_score(y_test_log, y_test_pred)\n",
    "\n",
    "# Training set MSE and R-squared\n",
    "mse_train = mean_squared_error(y_train_log, y_train_pred)\n",
    "r2_train = r2_score(y_train_log, y_train_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Test Set MSE: {mse_test}\")\n",
    "print(f\"Test Set R-squared: {r2_test}\")\n",
    "\n",
    "print(f\"Training Set MSE: {mse_train}\")\n",
    "print(f\"Training Set R-squared: {r2_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a44126a-f151-4a83-84c1-54b22d260e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the predictions against the true values for training and evaluation sets\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Training set plot\n",
    "axs[0].scatter(y_train_log, y_train_pred, color='blue', alpha=0.6)\n",
    "axs[0].plot([y_train_log.min(), y_train_log.max()], [y_train_log.min(), y_train_log.max()], color='red', linestyle='--')\n",
    "axs[0].set_title(\"Training Set: True vs Predicted\")\n",
    "axs[0].set_xlabel(\"True values (y_train_log)\")\n",
    "axs[0].set_ylabel(\"Predicted values (y_train_pred)\")\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Test set plot\n",
    "axs[1].scatter(y_test_log, y_test_pred, color='green', alpha=0.6)\n",
    "axs[1].plot([y_test_log.min(), y_test_log.max()], [y_test_log.min(), y_test_log.max()], color='red', linestyle='--')\n",
    "axs[1].set_title(\"Test Set: True vs Predicted\")\n",
    "axs[1].set_xlabel(\"True values (y_test_log)\")\n",
    "axs[1].set_ylabel(\"Predicted values (y_test_pred)\")\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d758df90-40e6-400a-9e1d-5517e42f596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting both training and evaluation set predictions together\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot training set\n",
    "plt.scatter(y_train_log, y_train_pred, color='blue', alpha=0.6, label='Training Set', s=20)\n",
    "\n",
    "# Plot evaluation set\n",
    "plt.scatter(y_eval_log, y_eval_pred, color='green', alpha=0.6, label='Evaluation Set', s=20)\n",
    "\n",
    "# Plot test set\n",
    "plt.scatter(y_test_log, y_test_pred, color='pink', alpha=0.6, label='Test Set', s=20)\n",
    "\n",
    "# Plot a line for perfect prediction (y_true = y_pred)\n",
    "plt.plot([min(y_train_log.min(), y_test_log.min(), y_eval_log.min()), \n",
    "          max(y_train_log.max(), y_test_log.max(), y_eval_log.max())],\n",
    "         [min(y_train_log.min(), y_test_log.min(), y_eval_log.min()), \n",
    "          max(y_train_log.max(), y_test_log.max(), y_eval_log.max())],\n",
    "         color='red', linestyle='--', label='Perfect Prediction')\n",
    "\n",
    "# Set labels and title\n",
    "plt.title(\"True vs Predicted Values for Training, Evaluation, and Test Sets\")\n",
    "plt.xlabel(\"True values\")\n",
    "plt.ylabel(\"Predicted values\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15253ba-9be6-47ac-a079-2b614ea976cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the values\n",
    "data = {\n",
    "    'Dataset': ['Test Set', 'Training Set', 'Evaluation Set'],\n",
    "    'MSE': [0.2664, 0.0127, 0.2480],\n",
    "    'R-squared': [0.4125, 0.9697, 0.9697]\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "metrics_table = pd.DataFrame(data)\n",
    "metrics_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e959e183-7954-4ddc-b0df-1a35f1027d61",
   "metadata": {},
   "source": [
    " ### Plotting the Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd06230-6ea4-4058-ae4a-a9497aa9e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Learning Curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the best hyperparameters based on your search\n",
    "best_params = {\n",
    "    'subsample': 0.7,\n",
    "    'n_estimators': 400,\n",
    "    'max_depth': 7,\n",
    "    'learning_rate': 0.2,\n",
    "    'colsample_bytree': 0.6\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost model with the best parameters\n",
    "best_xgb_model = xgb.XGBRegressor(\n",
    "    subsample=best_params['subsample'],\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    colsample_bytree=best_params['colsample_bytree'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "best_xgb_model.fit(X_train_log, y_train_log)\n",
    "\n",
    "# Predict on the training and test set\n",
    "y_train_pred = best_xgb_model.predict(X_train_log)\n",
    "y_test_pred = best_xgb_model.predict(X_test_log)\n",
    "\n",
    "# Calculate MSE and R-squared for the test and training set\n",
    "mse_train = mean_squared_error(y_train_log, y_train_pred)\n",
    "r2_train = r2_score(y_train_log, y_train_pred)\n",
    "\n",
    "mse_test = mean_squared_error(y_test_log, y_test_pred)\n",
    "r2_test = r2_score(y_test_log, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Training Set MSE: {mse_train}\")\n",
    "print(f\"Training Set R-squared: {r2_train}\")\n",
    "print(f\"Test Set MSE: {mse_test}\")\n",
    "print(f\"Test Set R-squared: {r2_test}\")\n",
    "\n",
    "# Plot the learning curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    best_xgb_model, X_train_log, y_train_log, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Calculate the mean and standard deviation for the train and test scores\n",
    "train_mean = -train_scores.mean(axis=1)  # Convert negative MSE back to positive\n",
    "test_mean = -test_scores.mean(axis=1)    # Convert negative MSE back to positive\n",
    "train_std = train_scores.std(axis=1)\n",
    "test_std = test_scores.std(axis=1)\n",
    "\n",
    "# Plot learning curves for MSE\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, label='Training error', color='blue')\n",
    "plt.plot(train_sizes, test_mean, label='Test error', color='green')\n",
    "\n",
    "# Plot the shaded area for the standard deviation\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.2)\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color='green', alpha=0.2)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Learning Curve with Best Hyperparameters')\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a1d9c0-d78c-4dce-92b7-3aa90daa9ab7",
   "metadata": {},
   "source": [
    "- Investigating the wide gap b/w test set and train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015e96c-db7a-414b-a24d-d924244be54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for data leakage\n",
    "\n",
    "#Check if there is any overlap between training and test sets\n",
    "overlap = X_train.index.intersection(X_test.index)\n",
    "if len(overlap) > 0:\n",
    "    print(f\"Warning: There is overlap in the training and test sets. Overlapping samples: {len(overlap)}\")\n",
    "else:\n",
    "    print(\"No overlap between training and test sets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd63949a-5862-4506-a4f6-1bdc682f277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation between features in X_train and the target y_train\n",
    "X_train['Appliances'] = y_train  # Add Appliances to X_train temporarily for correlation\n",
    "correlation_matrix = X_train.corr()\n",
    "print(correlation_matrix['Appliances'])\n",
    "\n",
    "#There is no specific feature which is highly correlated with the target.\n",
    "# This means no indication of data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c619e7-5996-45d5-af88-2231e58593e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "#Transforming back to original scale and computing for actual energy of the predicted:\n",
    "\n",
    "# Convert Predictions and Actual Values Back to Original Scale\n",
    "y_train_pred_orig = np.exp(y_train_pred)  # Convert predictions back\n",
    "y_test_pred_orig = np.exp(y_test_pred)\n",
    "y_eval_pred_orig = np.exp(y_eval_pred)  # If you have an evaluation set\n",
    "\n",
    "y_train_orig = np.exp(y_train_log)  # Convert actual values back\n",
    "y_test_orig = np.exp(y_test_log)\n",
    "y_eval_orig = np.exp(y_eval_log)  # If applicable\n",
    "\n",
    "# Compute MSE in Original Scale\n",
    "train_mse_orig = mean_squared_error(y_train_orig, y_train_pred_orig)\n",
    "test_mse_orig = mean_squared_error(y_test_orig, y_test_pred_orig)\n",
    "eval_mse_orig = mean_squared_error(y_eval_orig, y_eval_pred_orig)\n",
    "\n",
    "print(f\"Training MSE (original scale): {train_mse_orig}\")\n",
    "print(f\"Test MSE (original scale): {test_mse_orig}\")\n",
    "print(f\"Evaluation MSE (original scale): {eval_mse_orig}\")\n",
    "\n",
    "# Compute Average Difference (to check energy savings)\n",
    "train_diff = y_train_orig - y_train_pred_orig\n",
    "test_diff = y_test_orig - y_test_pred_orig\n",
    "eval_diff = y_eval_orig - y_eval_pred_orig  # If applicable\n",
    "\n",
    "print(f\"Average Training Difference: {train_diff.mean()}\")\n",
    "print(f\"Average Test Difference: {test_diff.mean()}\")\n",
    "print(f\"Average Evaluation Difference: {eval_diff.mean()}\")\n",
    "\n",
    "# Create a DataFrame for Comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Actual Energy (Test)\": y_test_orig,\n",
    "    \"Predicted Energy (Test)\": y_test_pred_orig,\n",
    "    \"Difference\": test_diff\n",
    "})\n",
    "\n",
    "print(\"\\nSample of Actual vs Predicted Energy Consumption:\")\n",
    "print(comparison_df.head())  # Show first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a24299-a69f-4438-942c-ee153f6368d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Predicted Energy\n",
    "\n",
    "total_predicted_energy = df['Predicted Energy'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb463f8-8027-4d2d-8183-3f2f931f66bc",
   "metadata": {},
   "source": [
    "#### The MSE result has been transformed back from log to compare with the actual appliance energy consumption.  Hence, below are limitations so it cannot be achieved:\n",
    "\n",
    "1. The r^2 predicting only 68% of the actual, meaning it has 32% chance of incorrect prediction. This result is not agreeable especially when predicting cost.\n",
    "2. This will be the same for the total green house gas emission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
