{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49dca7e7-026d-433b-9399-57f2ce1e5a56",
   "metadata": {},
   "source": [
    "## Predicting Energy Consumption in Low Energy Houses Using Data Driven Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be59678-ee98-4d22-9e3b-043e3bc4ab07",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8656e88-c7b8-448e-81e6-222e1bc55bde",
   "metadata": {},
   "source": [
    "Data Set is from https://www.kaggle.com/datasets/sohommajumder21/appliances-energy-prediction-data-set oroginally from https://archive.ics.uci.edu/dataset/374/appliances+energy+prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b3c2b9-de4c-4d5c-8045-c6a4b1cb62af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a7b0da-d82d-424f-861f-97daf590c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "df = pd.read_csv('energydata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447927e5-2d27-41df-a020-3ebbc1a9560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect appearance of rows and columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fe8646-dea5-4808-a89b-ac6b8ebee070",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de7240-d112-4b58-acb4-c7b7c9965978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking dimensionality\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3898c058-3f96-4f80-9250-ffe1816b4de8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#looking for data that needs to be converted (date column is non-numerical)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f07964f-e0e2-4cf6-bf21-d0dbde34d25e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#no missing value\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666f1767-b1b7-41d0-85ec-01c4d7e892c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no duplicate in any row or column, all are unique values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f905d21-659d-4acb-8add-9c644de79496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()\n",
    "#Generally, the data set which is 19735x29 is already clean, and date is the only object type of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9060fb-5cd7-4df2-ade8-62849a14e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive Statistics\n",
    "df.describe()\n",
    "#of all the 29 variables, the target \"Appliance\" has the highest std at 102.52 WH which indicates wide variance and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d611fe2b-5653-4346-bec9-493b324758a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets set the dictionary to further undesrtand the graphs\n",
    "\n",
    "#dictionary to store the units for each column\n",
    "columns_units = {\n",
    "    'Appliances': 'energy (Wh)',\n",
    "    'lights': 'energy (Wh)',\n",
    "    'T1': 'Temperature:kitchen, degC',\n",
    "    'RH_1': 'Humidity:kitchen, %',\n",
    "    'T2': 'Temperature:living rm, degC',\n",
    "    'RH_2': 'Humidity:living rm, %',\n",
    "    'T3': 'Temperature:laundry rm, degC',\n",
    "    'RH_3': 'Humidity:laundry rm, %',\n",
    "    'T4': 'Temperature:office rm, degC',\n",
    "    'RH_4': 'Humidity:office rm, %',\n",
    "    'T5': 'Temperature:bathroom, degC',\n",
    "    'RH_5': 'Humidity:bathroom, %',\n",
    "    'T6': 'Temperature outside bldg (North), degC',\n",
    "    'RH_6': 'Humidity outside bldg (North), %',\n",
    "    'T7': 'Temperature:ironing rm, degC',\n",
    "    'RH_7': 'Humidity:ironing rm, %',\n",
    "    'T8': 'Temperature: teen\\'s rm 2, degC',\n",
    "    'RH_8': 'Humidity:teen\\'s rm2, %',\n",
    "    'T9': 'Temperature:parents rm, degC',\n",
    "    'RH_9': 'Humidity:parents rm, %',\n",
    "    'T_out': 'Temperature outside, degC',\n",
    "    'Press_mm_hg': 'Pressure outside, mmHg',\n",
    "    'RH_out': 'Humidity outside, %',\n",
    "    'Windspeed': 'Wind speed, outside, m/s',\n",
    "    'Visibility': 'Visibility, outside, km',\n",
    "    'Tdewpoint': 'Dewpoint, outside, Â°C',\n",
    "    'rv1': 'Random var1',\n",
    "    'rv2': 'Random var2'\n",
    "}\n",
    "\n",
    "# Adjust the figure size\n",
    "plt.figure(figsize=(15, 10))  \n",
    "\n",
    "# Loop over columns and create subplots\n",
    "for i, col in enumerate(df.columns):\n",
    "    plt.subplot(6, 5, i + 1)  \n",
    "    sns.histplot(df[col], kde=True)  # kde=True adds the density plot\n",
    "    \n",
    "    # Set the title of the plot (Cplot title)\n",
    "    plt.title(f\"{col}\")\n",
    "    \n",
    "    # Set the x-axis label as the column name from the dictionary\n",
    "    plt.xlabel(f\"{columns_units.get(col, '')}\")  # Get the unit from the dictionary \n",
    "    plt.ylabel(\"Density\")  # The y-axis label remains as \"Density\"\n",
    "\n",
    "# Adjust layout to prevent overlapping of titles and labels\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#The dependent variable \"Appliances \" showed skewed distribution with long tail to the right\n",
    "#The independent variables on the other hand showed different types of distribution  like:\n",
    "\n",
    "## T1,RH1,T2,RH2,T4,RH5,T6,Dewpoint,Temp_outside, Pressure_outside looks normal distrubution with slight skwedness\n",
    "## T3,RH3,RH4,T5,T7,RH8,T9,RH9 are whosing twin peaks which could indicate mix of two different process or population\n",
    "## RH6 looks to be no patern at all\n",
    "## date is just a one block which is expected as it a uniform data collection in 10mins interval from Jan-May 2016\n",
    "## rv1 and rv2 are synthetic data included to represent uncertain factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c70586-7aa3-4408-bfa1-ef983b12d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the figure size for the boxplots\n",
    "plt.figure(figsize=(15, 10))  # Adjust the figure size if necessary\n",
    "\n",
    "# Loop over columns and create subplots for boxplots\n",
    "for i, col in enumerate(df.columns):\n",
    "    plt.subplot(6, 5, i + 1)  # Adjust the number of rows and columns for better layout (6 rows, 5 columns)\n",
    "    sns.boxplot(x=df[col])  # Create a boxplot for the column\n",
    "    \n",
    "    # Set the title of the plot (Column name as the plot title)\n",
    "    plt.title(f\"{col}\")\n",
    "    \n",
    "    # Set the x-axis label as the column name with the unit from the dictionary\n",
    "    plt.xlabel(f\"{columns_units.get(col, '')}\")  # Get the unit from the dictionary (default empty string if not found)\n",
    "    plt.ylabel(\"Value\")  # The y-axis label remains as \"Value\"\n",
    "\n",
    "# Adjust layout to prevent overlapping of titles and labels\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Outliers are almost present in all variables, eepcially target ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf51ce2-f568-4f62-82f6-390c200a4a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Transformation by Extracting parts of a date-time feature (feature engineering app#1)\n",
    "\n",
    "# Convert 'date' column to datetime format (without dropping the original)\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d-%m-%Y %H:%M', errors='coerce')\n",
    "\n",
    "# Extract numerical features from the 'date' column,\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df['hour'] = df['date'].dt.hour\n",
    "df['minute'] = df['date'].dt.minute\n",
    "\n",
    "#New data shape after date transformation: 19735x33 (including original date column and target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b92139-09aa-49f3-b676-846efb8744f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new df (year,month,day,hour and minute were separated and added as new columns)\n",
    "df_new = df.copy()\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f212e3-df2a-4199-b1b7-9654498fd817",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tried to to do a date-series graph, output doesnt seem to be correct. Used excel to plot in the end.\n",
    "# Set 'date' as the index for df_new\n",
    "df_new.set_index('date', inplace=True)\n",
    "\n",
    "# Select only numeric columns (exclude 'date' and any non-numeric columns)\n",
    "df_numeric = df_new.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Resample data to 5-hour intervals (same day) and aggregate using mean\n",
    "df_resampled = df_numeric.resample('5H').mean()\n",
    "\n",
    "# Extract the relevant features for the plot\n",
    "df_selected = df_resampled[['T2', 'T6', 'Appliances', 'lights']]\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot temperature features (T2 and T6) on the first y-axis\n",
    "ax1.plot(df_selected.index, df_selected['T2'], label='Temperature:living rm, degC', color='tab:blue', alpha=0.7)\n",
    "ax1.plot(df_selected.index, df_selected['T6'], label='Temperature outside bldg (North), degC', color='tab:orange', alpha=0.7)\n",
    "\n",
    "# Formatting for the first y-axis\n",
    "ax1.set_xlabel(\"Date and Hour\")\n",
    "ax1.set_ylabel(\"Temperature (Â°C)\", color='tab:blue')\n",
    "ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# Create a second y-axis for energy values\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(df_selected.index, df_selected['Appliances'], label='Energy from Appliances (Wh)', color='tab:green', alpha=0.7)\n",
    "ax2.plot(df_selected.index, df_selected['lights'], label='Energy from Lights (Wh)', color='tab:red', alpha=0.7)\n",
    "\n",
    "# Formatting for the second y-axis\n",
    "ax2.set_ylabel(\"Energy (Wh)\", color='tab:green')\n",
    "ax2.tick_params(axis='y', labelcolor='tab:green')\n",
    "\n",
    "# Customize x-axis labels to show both date and time (YYYY-MM-DD HH:MM format)\n",
    "ax1.set_xticklabels(df_selected.index.strftime('%Y-%m-%d %H:%M'), rotation=45)\n",
    "\n",
    "# Title and legend\n",
    "plt.title(\"Time-Series Plot of Temperature and Energy Features (5-Hour Interval)\")\n",
    "ax1.legend(loc='upper left', fontsize=8)\n",
    "ax2.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda6acc-8dae-4865-9a35-5bb9852ad26d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reset the index to make 'date' a column\n",
    "df_new.reset_index(inplace=True)\n",
    "\n",
    "# Convert 'date' column to datetime format\n",
    "df_new['date'] = pd.to_datetime(df_new['date'])\n",
    "\n",
    "# Set 'date' as the index for df_new\n",
    "df_new.set_index('date', inplace=True)\n",
    "\n",
    "# Select only numeric columns (exclude 'date' and any non-numeric columns)\n",
    "df_numeric = df_new.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Resample data to 5-hour intervals (same day) and aggregate using mean\n",
    "df_resampled = df_numeric.resample('5H').mean()\n",
    "\n",
    "# Loop through each numeric feature and plot with respect to 'lights'\n",
    "for feature in df_resampled.columns:\n",
    "    if feature != 'lights':  # Skip plotting 'lights' against itself\n",
    "        # Create the figure and axes for each feature\n",
    "        fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "        # Plot the selected feature on the first y-axis\n",
    "        ax1.plot(df_resampled.index, df_resampled[feature], label=f'{feature}', color='tab:blue', alpha=0.7)\n",
    "\n",
    "        # Formatting for the first y-axis\n",
    "        ax1.set_xlabel(\"Date and Hour\")\n",
    "        ax1.set_ylabel(f\"{feature} (Unit)\", color='tab:blue')\n",
    "        ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "        # Create a second y-axis for energy values ('lights')\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(df_resampled.index, df_resampled['lights'], label='Energy from Lights (Wh)', color='tab:red', alpha=0.7)\n",
    "\n",
    "        # Formatting for the second y-axis\n",
    "        ax2.set_ylabel(\"Energy (Wh)\", color='tab:red')\n",
    "        ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "        # Customize x-axis labels to show both date and time (YYYY-MM-DD HH:MM format)\n",
    "        ax1.set_xticklabels(df_resampled.index.strftime('%Y-%m-%d %H:%M'), rotation=45)\n",
    "\n",
    "        # Title and legend\n",
    "        plt.title(f\"Time-Series Plot of {feature} and Energy from Lights (5-Hour Interval)\")\n",
    "        ax1.legend(loc='upper left', fontsize=8)\n",
    "        ax2.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "        # Show the plot\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Display the plot for each feature\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1bb3af-428b-49d6-ba57-907e8d23d997",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the figure with 3 subplots (for Daily, Weekly, and Monthly data)\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12, 15), sharex=True)\n",
    "\n",
    "# Daily Data Plot\n",
    "# Plot appliances and lights (energy in Wh) on the left y-axis\n",
    "df_new.resample('D').mean()['Appliances'].plot(ax=axs[0], color='tab:blue', label='Appliances (Wh)')\n",
    "df_new.resample('D').mean()['lights'].plot(ax=axs[0], color='tab:orange', label='Lights (Wh)')\n",
    "\n",
    "# Plot features like RH_1 on the right y-axis\n",
    "ax2 = axs[0].twinx()  \n",
    "df_new.resample('D').mean()['RH_1'].plot(ax=ax2, color='tab:green', label='Humidity: kitchen (%)', linestyle='--')\n",
    "\n",
    "# Add labels and title for the first subplot\n",
    "axs[0].set_ylabel(\"Energy (Wh)\", color='tab:blue')\n",
    "ax2.set_ylabel(\"Humidity (%)\", color='tab:green')\n",
    "axs[0].set_title(\"Daily Energy and Features\")\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Weekly Data Plot\n",
    "# Plot appliances and lights (energy in Wh) on the left y-axis\n",
    "df_new.resample('W').mean()['Appliances'].plot(ax=axs[1], color='tab:blue', label='Appliances (Wh)')\n",
    "df_new.resample('W').mean()['lights'].plot(ax=axs[1], color='tab:orange', label='Lights (Wh)')\n",
    "\n",
    "# Plot features like T1 on the right y-axis\n",
    "ax2 = axs[1].twinx()  \n",
    "df_new.resample('W').mean()['T1'].plot(ax=ax2, color='tab:red', label='Temperature: kitchen (Â°C)', linestyle='--')\n",
    "\n",
    "# Add labels and title for the second subplot\n",
    "axs[1].set_ylabel(\"Energy (Wh)\", color='tab:blue')\n",
    "ax2.set_ylabel(\"Temperature (Â°C)\", color='tab:red')\n",
    "axs[1].set_title(\"Weekly Energy and Features\")\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Monthly Data Plot\n",
    "# Plot appliances and lights (energy in Wh) on the left y-axis\n",
    "df_new.resample('M').mean()['Appliances'].plot(ax=axs[2], color='tab:blue', label='Appliances (Wh)')\n",
    "df_new.resample('M').mean()['lights'].plot(ax=axs[2], color='tab:orange', label='Lights (Wh)')\n",
    "\n",
    "# Plot features like RH_2 on the right y-axis\n",
    "ax2 = axs[2].twinx()  \n",
    "df_new.resample('M').mean()['RH_2'].plot(ax=ax2, color='tab:green', label='Humidity: living room (%)', linestyle='--')\n",
    "\n",
    "# Add labels and title for the third subplot\n",
    "axs[2].set_ylabel(\"Energy (Wh)\", color='tab:blue')\n",
    "ax2.set_ylabel(\"Humidity (%)\", color='tab:green')\n",
    "axs[2].set_title(\"Monthly Energy and Features\")\n",
    "axs[2].grid(True)\n",
    "\n",
    "# Format the x-axis labels to be readable\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.legend(loc='upper left')\n",
    "\n",
    "# Adjust layout for better spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2381d8-06c3-4b83-b055-ab8fe5b99360",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List of feature columns to plot (excluding time-related and energy columns)\n",
    "feature_columns = [\n",
    "    'T1', 'RH_1', 'T2', 'RH_2', 'T3', 'RH_3', 'T4', 'RH_4', 'T5', 'RH_5',\n",
    "    'T6', 'RH_6', 'T7', 'RH_7', 'T8', 'RH_8', 'T9', 'RH_9', 'T_out', 'Press_mm_hg',\n",
    "    'RH_out', 'Windspeed', 'Visibility', 'Tdewpoint', 'rv1', 'rv2'\n",
    "]\n",
    "\n",
    "# Create the figure with subplots (3 for daily, weekly, and monthly data)\n",
    "fig, axs = plt.subplots(len(feature_columns), 3, figsize=(15, len(feature_columns)*5), sharex=True)\n",
    "\n",
    "# Loop through each feature\n",
    "for i, feature in enumerate(feature_columns):\n",
    "    # Plot daily data\n",
    "    df_new.resample('D').mean()['Appliances'].plot(ax=axs[i, 0], color='tab:blue', label='Appliances (Wh)')\n",
    "    df_new.resample('D').mean()['lights'].plot(ax=axs[i, 0], color='tab:orange', label='Lights (Wh)')\n",
    "    ax2 = axs[i, 0].twinx()\n",
    "    df_new.resample('D').mean()[feature].plot(ax=ax2, color='tab:green', label=feature, linestyle='--')\n",
    "    axs[i, 0].set_title(f\"Daily: Energy and {feature}\")\n",
    "    axs[i, 0].set_ylabel(\"Energy (Wh)\", color='tab:blue')\n",
    "    ax2.set_ylabel(f\"{feature} Value\", color='tab:green')\n",
    "    axs[i, 0].grid(True)\n",
    "    \n",
    "    # Plot weekly data\n",
    "    df_new.resample('W').mean()['Appliances'].plot(ax=axs[i, 1], color='tab:blue', label='Appliances (Wh)')\n",
    "    df_new.resample('W').mean()['lights'].plot(ax=axs[i, 1], color='tab:orange', label='Lights (Wh)')\n",
    "    ax2 = axs[i, 1].twinx()\n",
    "    df_new.resample('W').mean()[feature].plot(ax=ax2, color='tab:green', label=feature, linestyle='--')\n",
    "    axs[i, 1].set_title(f\"Weekly: Energy and {feature}\")\n",
    "    axs[i, 1].set_ylabel(\"Energy (Wh)\", color='tab:blue')\n",
    "    ax2.set_ylabel(f\"{feature} Value\", color='tab:green')\n",
    "    axs[i, 1].grid(True)\n",
    "    \n",
    "    # Plot monthly data\n",
    "    df_new.resample('ME').mean()['Appliances'].plot(ax=axs[i, 2], color='tab:blue', label='Appliances (Wh)')\n",
    "    df_new.resample('ME').mean()['lights'].plot(ax=axs[i, 2], color='tab:orange', label='Lights (Wh)')\n",
    "    ax2 = axs[i, 2].twinx()\n",
    "    df_new.resample('ME').mean()[feature].plot(ax=ax2, color='tab:green', label=feature, linestyle='--')\n",
    "    axs[i, 2].set_title(f\"Monthly: Energy and {feature}\")\n",
    "    axs[i, 2].set_ylabel(\"Energy (Wh)\", color='tab:blue')\n",
    "    ax2.set_ylabel(f\"{feature} Value\", color='tab:green')\n",
    "    axs[i, 2].grid(True)\n",
    "\n",
    "# Format the x-axis labels to be readable (rotate them)\n",
    "for ax in axs.flatten():\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.legend(loc='upper left', fontsize=8)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "\n",
    "# Adjust layout for better spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ccee67-e94d-4a75-9ad6-8f529747bc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[['T2', 'T_out', 'RH_out', 'Appliances','lights','hour','Tdewpoint','Windspeed','Visibility']])  # features of interest\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae665863-b42a-4e5e-bc51-6622ac1fb3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding relationship of features with the target variable \"Appliances\"\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df_new.corr()\n",
    "\n",
    "# Create a mask for the upper triangle of the correlation matrix\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Create the heatmap with the mask applied\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', mask=mask, vmin=-1, vmax=1, cbar_kws={'shrink': 0.8})\n",
    "\n",
    "# Add title\n",
    "plt.title('Correlation Heatmap')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "#we can observe highly correlated features as well as an observation of\n",
    "#synthetic data being present in the data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb396940-1443-40a6-a6d1-b3fbace08079",
   "metadata": {},
   "source": [
    "### Data Preparation and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5767ba08-6962-499a-b5da-e7eeaaa98a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data set into Training, Evaluation, and Test Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define your features and target\n",
    "df_new = df_new.reset_index(drop=True)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2146e9-97b8-4368-b185-a3f2f3739030",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_new.drop(columns=['Appliances','year'])  # Exclude the target and year column\n",
    "y = df_new['Appliances']  # Target variable\n",
    "\n",
    "# Split the data into training (70%), evaluation (15%), and test (15%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_eval, X_test, y_eval, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Check the shape of the resulting splits\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Evaluation set size: {X_eval.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "\n",
    "#the columns increased from 28 to 33 as the date was transformed in year\n",
    "#,month,dat,hour, and minute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a1821-4a67-4ef8-88b9-0d9d31293036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation of each feature with the target variable (y_train)\n",
    "correlation_with_target = X_train.apply(lambda x: x.corr(y_train))\n",
    "\n",
    "# Define your thresholds\n",
    "thresholds = [0.03, 0.05, 0.075, 0.1]\n",
    "\n",
    "# Initialize a list to store selected features at each threshold\n",
    "selected_features_at_thresholds = {}\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Select features based on correlation threshold\n",
    "    selected_features = correlation_with_target[correlation_with_target.abs() > threshold].index\n",
    "    \n",
    "    # Store the selected features for this threshold\n",
    "    selected_features_at_thresholds[threshold] = selected_features\n",
    "\n",
    "    print(f\"Threshold: {threshold}, Features selected: {len(selected_features)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e0438-a82e-47a9-aeff-b496b616af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store selected features for each threshold\n",
    "selected_features_at_thresholds = {}\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Select features based on correlation threshold\n",
    "    selected_features = correlation_with_target[correlation_with_target.abs() > threshold].index.tolist()\n",
    "    \n",
    "    # Store the selected features\n",
    "    selected_features_at_thresholds[threshold] = selected_features\n",
    "\n",
    "    # Print threshold and selected features\n",
    "    print(f\"\\nThreshold: {threshold}, Features selected: {len(selected_features)}\")\n",
    "    print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3e107a-8db9-4e5e-b9b4-bc896355ae90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the actual correlation values with the target for each feature\n",
    "print(correlation_with_target)\n",
    "#the correlation values was reduced compared to the overall correlatio due to \n",
    "#data splitting (using training set which is only 70% of the data set), n the feature selection step, you are computing the \n",
    "#correlation only between features and the target variable (y_train), which can be much weaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dde50f-0e8d-4ad4-b6fa-904613abe10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#double check if the subset is representing the whole data set\n",
    "# Select a feature that had high correlation in the full dataset\n",
    "feature = 'T_out'  # 0.97\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df_new[feature], color='blue', label='Full Data', kde=True)\n",
    "sns.histplot(X_train[feature], color='red', label='Training Data', kde=True)\n",
    "plt.legend()\n",
    "plt.title(f\"Distribution of {feature} in Full vs. Training Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24186f0b-a60f-4584-9a4a-e52d987fcf36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute Spearman correlation instead of Pearson\n",
    "spearman_correlation = X_train.corrwith(y_train, method='spearman').sort_values(ascending=False)\n",
    "print(spearman_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af1c2ea-12e3-421d-9885-f36516768116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the data set  is linear or non-linear using Pearson (linear) and Spearman (non-linear) correlation\n",
    "\n",
    "# Compute Pearson correlation\n",
    "pearson_corr = X_train.corrwith(y_train, method='pearson')\n",
    "\n",
    "# Compute Spearman correlation\n",
    "spearman_corr = X_train.corrwith(y_train, method='spearman')\n",
    "\n",
    "# Combine both into a DataFrame\n",
    "correlation_df = pd.DataFrame({'Pearson': pearson_corr, 'Spearman': spearman_corr})\n",
    "\n",
    "# Sort by absolute Pearson correlation for better visualization\n",
    "correlation_df = correlation_df.reindex(pearson_corr.abs().sort_values(ascending=False).index)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "correlation_df.plot(kind='bar', figsize=(15, 5), width=0.8, colormap='coolwarm')\n",
    "plt.axhline(y=0, color='black', linewidth=0.8)  # Add a reference line at 0\n",
    "plt.title(\"Pearson vs. Spearman Correlation with Target (Appliances)\")\n",
    "plt.ylabel(\"Correlation Coefficient\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "#Spearman Correlation > Pearson, meaning features have non-linear relationship with the target\n",
    "# This suggest that feature selection based on correlation is not the recommende featue emgineering approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611fef71-2b90-46d2-afae-e01f874b2d14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Further Checking Pearson and Spearman scores with  Mutual Information Regression\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "mi = mutual_info_regression(X_train, y_train)\n",
    "mi_series = pd.Series(mi, index=X_train.columns).sort_values(ascending=False)\n",
    "print(mi_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c127241-0f7b-4c77-b2a8-2d493af04c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Pearson, Spearman, and Mutual Information into a DataFrame and plot\n",
    "\n",
    "correlation_df = pd.DataFrame({\n",
    "    'Pearson': pearson_corr,\n",
    "    'Spearman': spearman_corr,\n",
    "    'Mutual Info': mi_series\n",
    "})\n",
    "\n",
    "# Sort by highest mutual information for better visualization\n",
    "correlation_df = correlation_df.reindex(mi_series.sort_values(ascending=False).index)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 6))\n",
    "correlation_df.plot(kind='bar', figsize=(15, 5), width=0.8, colormap='coolwarm')\n",
    "plt.axhline(y=0, color='black', linewidth=0.8)  # Reference line at 0\n",
    "plt.title(\"Feature Importance: Pearson vs. Spearman vs. Mutual Information\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b4c4d1-a0e9-435e-a99f-eb0627a9438f",
   "metadata": {},
   "source": [
    "#### Interpretation:\n",
    "- Spearman > Pearson indicates that as one variable increases, the other consistently increase or decrease but at variable rate,and is not perfectly linear,\n",
    "- Mutual info of RH_6, Press_mm_hg,RH2,RH9,RH7,and RH_out have positive score while Pearson and Spearman are on negative score-this indicates complex interactions.\n",
    "- RH5 and RH3 has (+) score on Pearson and Mutual Info but (-) in Spearman, there is likely a non-monotonic but partially linear relationship with the target. Additionally, Mutual Information is (+) verifies that RH5 and RH3 contain predictive information about the dependent variable, even if the relationship isnât purely linear or monotonic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce0f22a-593f-47fc-8ad8-f7efbd7f6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veryfying the (-) Spearman with (+) Pearson & MI score\n",
    "for feature in ['RH_3', 'RH_5']:\n",
    "    sns.lmplot(x=feature, y='Appliances', data=df_new, lowess=True)\n",
    "    plt.title(f'Lowess Curve for {feature} vs Appliances')\n",
    "    plt.show()\n",
    "\n",
    "#These scatter plot doesnt seem to show high pattern to indicate relationship with Appliances\n",
    "# RH_3 and RH_5 is not inidcative as having direct relationship with the target, instead the outliers could be distorting \n",
    "# the Spearman scores thus may be giving incorrect information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765bca2-08f8-4452-b080-df418a2cd9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for outliers, this can be distorting Spearman score which explains the unclear scatter plot pattern\n",
    "\n",
    "sns.boxplot(x=df_new['RH_3'])\n",
    "plt.show()\n",
    "sns.boxplot(x=df_new['RH_5'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fcd1db-30b6-45bf-9fbc-65cf47a00eba",
   "metadata": {},
   "source": [
    "- Feature selection using correlation is not the best approach as indicated by the higher Spearman score over Pearson corelation value.\n",
    "- Thus Recursive Feature Elimination will be checked using the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b49cc71-2f6e-4f22-b2e4-20d725166d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for skweness\n",
    "# Identify highly skewed features\n",
    "skewed_features = X_train.skew().sort_values(ascending=False)\n",
    "highly_skewed = skewed_features[skewed_features > 0.75].index\n",
    "\n",
    "# Plot histograms\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, col in enumerate(highly_skewed[:6]):  # Limit to first 6 for readability\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    sns.histplot(X_train[col], bins=30, kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73a2daf-ef76-4b24-a645-e40ac19330c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(skewed_features[skewed_features > 0.75]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b32c72-4e54-47a1-afcf-e6397bc7d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for i, col in enumerate(highly_skewed[:6]):  # Limit to first 6\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    sns.boxplot(x=X_train[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c478aa-a4d6-4b10-9471-dea7a25ba3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=skewed_features.index, y=skewed_features.values, palette=\"viridis\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Skewness\")\n",
    "plt.title(\"Skewness of Features in X_train\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219ec31-7113-47bb-9aae-f0ea3ef742e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipping the skweness issue, as this is more advantageous in linear relationships\n",
    "# Instead focus on Models whihc are Tree-Based () Random Forest, Gradient Boosting, XGBoost) and Neural Network\n",
    "# these models focus on non-linear relationships and less sensitive to skewness and outliers\n",
    "# Will not apply transformation for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc51f7-6a7a-4a69-97d8-30f7504f8447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df_new' is your original dataset\n",
    "X_train = df_new.drop(columns=['Appliances', 'year'])\n",
    "\n",
    "# Split the data again as you did before (if needed)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_eval, X_test, y_eval, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1007e2d4-c0df-4797-aa77-0289758a2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the resulting splits\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Evaluation set size: {X_eval.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d713b7-51e3-407c-8c06-2b14c8de5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will select most impt features\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Compute MI Scores\n",
    "mi_scores = mutual_info_regression(X_train, y_train)\n",
    "mi_scores = pd.Series(mi_scores, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "# Select the top 15 features\n",
    "top_features = mi_scores.head(15).index.tolist()\n",
    "\n",
    "# Reduce feature set\n",
    "X_train = X_train[top_features]\n",
    "\n",
    "# Display selected features\n",
    "print(mi_scores.head(15))\n",
    "\n",
    "# mutual information regression, results in \n",
    "#MI scores that select the most relevant features the model. Features with higher MI scores can be prioritized,\n",
    "#while those with lower scores can be dropped to reduce dimensionality and avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151668a6-9d88-40c3-b717-519ee5b62a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the MI scores as a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "mi_scores.head(20).plot(kind='bar')\n",
    "plt.title('Top 15 Mutual Information Scores')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Mutual Information Score')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9b6b69-ba1a-41a6-8b60-8243b0bf586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Extract the feature importances\n",
    "feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to pair features with their importance scores\n",
    "importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the features by importance\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances as a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.title('Random Forest Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4850b8-8bd8-4b72-bc38-c97923c8561f",
   "metadata": {},
   "source": [
    "#### Summary of Feature engineering\n",
    "- Feature engineering is applied in the Training set, rows = 13814, columns=31 (exlude target and year)\n",
    "1. Dropping highly correlated features using correlation values was not use.\n",
    "   - The correlation values from the X_train falls mostly at 0.03 to 0.075 which indicates weak relationship between features and target. To verify if the train set is a representative of the whole data set, histogram of the highest correlation value in the whole dataset was plotted against the training set.\n",
    "   - This is verified using Spearman and Pearson correlation score. The comparison showed higher Spearman scores among the fetures, indicating a non-linear relationship.\n",
    "   - This is further checked by using the Mutual Information Regression score or Mi score. For most of the features Mi score is between  Spearman and Pearson, thus indicating\n",
    "2. Skwedness of the features in the traning set were checked but later left out as seen to be not very advantageous due to non-linear behavior of the independent variables to the dependent variables.\n",
    "3. MI scores (Mutual_info_regression) were used to identify top 15 features and these are hour,T9,T7,RH_6,T5,T4,T8,T1,T3,RH_1,Press_mm_hg,T_out,T2,RH_8, and RH_5.\n",
    "4. Recursive Feature engineering was also used to select the most important features. It gives hour,Press_mm_hg,T_out,T3,RH_1,RH_5,T8,RH_8,RH_6,T4,T7,T2,T5,T9, and T1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1f26e8-565f-4c37-b6ec-8a8c292cb6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from these, plot feature selection using Venn diagram \n",
    "\n",
    "from matplotlib_venn import venn2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Features selected by MI and RFE\n",
    "mi_features = {'hour', 'T9', 'T7', 'RH_6', 'T5', 'T4', 'T8', 'T1', 'T3', 'RH_1', 'Press_mm_hg', 'T_out', 'T2', 'RH_8', 'RH_5'}\n",
    "rfe_features = {'hour', 'Press_mm_hg', 'T_out', 'T3', 'RH_1', 'RH_5', 'T8', 'RH_8', 'RH_6', 'T4', 'T7', 'T2', 'T5', 'T9', 'T1'}\n",
    "\n",
    "# Create the Venn diagram\n",
    "plt.figure(figsize=(8, 6))\n",
    "venn2([mi_features, rfe_features], set_labels=('MI Scores', 'RFE'), alpha=0.5)\n",
    "plt.title(\"Venn Diagram of Features Selected by MI Scores and RFE\")\n",
    "plt.show()\n",
    "\n",
    "#These Venn diagram showed that the both Mutual_info_regression and\n",
    "# Recursive Feature elimination gave the same important features in relation the the dependent variable \"Appliances\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49c14cf-8cae-4b01-9e91-cdf7edafacfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the relationship of the top 15 features in the tsne\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9913f41-cb94-4dd8-ad12-255d7b6b9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the whole training set with top-15 features\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Initialize t-SNE model\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "# Fit and transform the training data using t-SNE\n",
    "X_train_tsne = tsne.fit_transform(X_train)\n",
    "\n",
    "# Create a scatter plot of the transformed data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1], c=y_train, cmap='viridis', s=20, alpha=0.7)\n",
    "plt.title(\"t-SNE visualization of top features from MI and RFE\")\n",
    "plt.xlabel(\"t-SNE component 1\")\n",
    "plt.ylabel(\"t-SNE component 2\")\n",
    "plt.colorbar(label='Appliances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea719fc-ea40-4d93-b62d-bc67e30e1190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot without diagonal elements\n",
    "sns.pairplot(X_train, corner=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f1ab3b-83ec-4d0e-9efc-0b4d3f1bd9c1",
   "metadata": {},
   "source": [
    "##### The top features doesn't seem to have specific scatter plots pattern\n",
    "##### The histogram showed different distrubution and a few  showed almost normal like RH_5,T2,T_out,Press_mm_hg,RH1,T8,T4.\n",
    "#### My final 15 features to be used in my modelling are: \n",
    "- Note: Temperaure are all in degC, RH is relative humidity in %\n",
    "1. hour = in 24 hours cycle\n",
    "2. T9 = Temp in parent's room, \n",
    "3. T7 = Temp in ironing roomm,\n",
    "4. RH_6 = HUmidity outside the building(North), \n",
    "5. T5 = Temp in  bathroom, \n",
    "6. T4 = Temp in office room\n",
    "7. T8 = Temp in teens room\n",
    "8. T1 = Temp in kitchen\n",
    "9. T3 = Temp in laundry\n",
    "10. RH_1 = Humidity in kitchen\n",
    "11. Press_mm_hg = Pressure outside, in mmHg\n",
    "12. T_out = Temp outside\n",
    "13. T2 = Temp in living room\n",
    "14. RH_8 = Humidity in teen's room\n",
    "15. RH_5 = Humidity in bathroom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d58b07-67e4-4340-9f5c-b4ea7699f552",
   "metadata": {},
   "source": [
    "#####  Next step is to proceed with modelling using SVM, Random Forest, Gradient Boosting, XGBoost, and Neural Netwrok .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943eb9ae-67b2-4bec-8193-a9f66b20663f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
